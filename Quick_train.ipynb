{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc467c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\yidaiyao\\AppData\\Local\\Temp/ipykernel_39052/1904467787.py\", line 533, in <module>\n",
      "    A2 = A1(z_mu)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 969, in __call__\n",
      "    return self._functional_construction_call(inputs, args, kwargs,\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1107, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 840, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 878, in _infer_output_signature\n",
      "    self._maybe_build(inputs)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 2625, in _maybe_build\n",
      "    self.build(input_shapes)  # pylint:disable=not-callable\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\", line 1191, in build\n",
      "    self.kernel = self.add_weight(\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 639, in add_weight\n",
      "    variable = self._add_variable_with_custom_getter(\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\", line 810, in _add_variable_with_custom_getter\n",
      "    new_variable = getter(\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\", line 127, in make_variable\n",
      "    return tf_variables.VariableV1(\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 260, in __call__\n",
      "    return cls._variable_v1_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 206, in _variable_v1_call\n",
      "    return previous_getter(\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 199, in <lambda>\n",
      "    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2612, in default_variable_creator\n",
      "    return resource_variable_ops.ResourceVariable(\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 264, in __call__\n",
      "    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 1584, in __init__\n",
      "    self._init_from_args(\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 1722, in _init_from_args\n",
      "    initial_value = initial_value()\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v2.py\", line 609, in __call__\n",
      "    q *= math_ops.sign(d)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 780, in sign\n",
      "    return gen_math_ops.sign(x, name=name)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 9080, in sign\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\yidaiyao\\.conda\\envs\\tf-gpu\\lib\\inspect.py\", line 745, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39052/1904467787.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m \u001b[0mA2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mB1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    970\u001b[0m                                                 input_list)\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1106\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1108\u001b[0m           inputs, input_masks, args, kwargs)\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    877\u001b[0m           \u001b[1;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2624\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2625\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint:disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2626\u001b[0m       \u001b[1;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m     self.kernel = self.add_weight(\n\u001b[0m\u001b[0;32m   1192\u001b[0m         \u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m     variable = self._add_variable_with_custom_getter(\n\u001b[0m\u001b[0;32m    640\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    809\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheckpoint_initializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m     new_variable = getter(\n\u001b[0m\u001b[0;32m    811\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    126\u001b[0m   \u001b[0mvariable_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   return tf_variables.VariableV1(\n\u001b[0m\u001b[0;32m    128\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    205\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     return previous_getter(\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2611\u001b[0m     \u001b[0mdistribute_strategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"distribute_strategy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2612\u001b[1;33m     return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[0;32m   2613\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1583\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1584\u001b[1;33m       self._init_from_args(\n\u001b[0m\u001b[0;32m   1585\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1721\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1722\u001b[1;33m               \u001b[0minitial_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1723\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor_diag_part\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m     \u001b[0mq\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_rows\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36msign\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m    779\u001b[0m         name=name)\n\u001b[1;32m--> 780\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msign\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m   9079\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9080\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   9081\u001b[0m         _ctx, \"Sign\", name, x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2060\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "##############import#################\n",
    "import h5py\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(33)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "# from tensorflow import keras\n",
    "from tensorflow.keras import layers,models,optimizers,callbacks,constraints\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D,multiply,Lambda,Add,Concatenate, Multiply,Conv2DTranspose,Layer, Reshape, ZeroPadding2D,Flatten, MaxPooling2D, UpSampling2D, BatchNormalization,LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,Callback,LearningRateScheduler,ModelCheckpoint\n",
    "# set_session(tf.Session(config=config))\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import os\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "jobid=int(0)\n",
    "param={i:[] for i in range(11)}\n",
    "param[0]=[2,1000,5,1000,500,15,'ppp']###################\n",
    "\n",
    "param[1]=[3,1,1000,1,10,20,'sr']\n",
    "param[2]=[2,1000,10,1,10,20,'sr']###\n",
    "param[3]=[2,0.001,1,1,5,20,'sr']###\n",
    "param[4]=[2,0.001,5,1,5,30,'sr']\n",
    "param[5]=[2,0.001,10,1,10,20,'sr']####\n",
    "param[6]=[3,100,5,1,10,20,'sr']###\n",
    "#############hyperparameter#################\n",
    "background=2\n",
    "udim=param[jobid][0]###\n",
    "sdim=5\n",
    "latent_dim=background+udim+sdim\n",
    "bac=2\n",
    "alpha=param[jobid][1]###\n",
    "beta=param[jobid][2]####\n",
    "gamma=param[jobid][3]####\n",
    "theta=param[jobid][4]####\n",
    "ks=param[jobid][5]####\n",
    "flag=param[jobid][6]####\n",
    "batch_size=10\n",
    "\n",
    "hdf5_file = 'data/part_data.hdf5' #Data available at: https://drive.google.com/file/d/1efgnHQ9ZXahn3-Z-boX9awmdq04XFKmZ/view?usp=sharing\n",
    "\n",
    "a = h5py.File(hdf5_file, 'r')\n",
    "\n",
    "name=list(a.keys())\n",
    "i1=a[name[1]]\n",
    "trail=list(i1.keys())\n",
    "# i12=i1[trail[1]]\n",
    "# # i12\n",
    "image_name=['images_30', 'images_36', 'images_46', 'images_57']\n",
    "label_name=['labels_30', 'labels_36', 'labels_46', 'labels_57']\n",
    "# print(name)\n",
    "va={i:[] for i in range (4)}\n",
    "\n",
    "for i in range (4):\n",
    "    imn=image_name[i]\n",
    "    lbn=image_name[i]\n",
    "    for j in trail:\n",
    "#         print(imn)\n",
    "        data=np.array(a[imn][j])\n",
    "        v=np.var(data,axis=0)\n",
    "        va[i].append(np.mean(v))\n",
    "\n",
    "so={i:[] for i in range (4)}\n",
    "vv={i:[] for i in range (4)}\n",
    "for i in range (4):\n",
    "    so[i]=np.argsort(np.array(va[i])*-1)\n",
    "    vv[i]=np.sort(np.array(va[i])*-1)\n",
    "\n",
    "\n",
    "z=0\n",
    "idx={i:[] for i in range (len(trail)*4*189)}\n",
    "for i in range(4):\n",
    "    seq=so[i]\n",
    "    for j in seq:\n",
    "        for k in range (189):\n",
    "            n=trail[j]\n",
    "            idx[z].append(i)\n",
    "            idx[z].append(n)\n",
    "            idx[z].append(k)\n",
    "            z+=1\n",
    "\n",
    "index=shuffle(idx)\n",
    "\n",
    "\n",
    "def data_generator(idx, hdf5file,batch_size,if_train = True):\n",
    "    i = 0\n",
    "#     j=0 \n",
    "    while True:\n",
    "        X = []\n",
    "        Y=[]\n",
    "        for b in range(batch_size):\n",
    "            if i == len(idx):\n",
    "                i = 0\n",
    "            \n",
    "            alll=idx[i]\n",
    "            if alll[0]==0:\n",
    "                imn='images_30'\n",
    "                lbn='labels_30'\n",
    "\n",
    "            elif alll[0]==1:\n",
    "                imn='images_36'\n",
    "                lbn='labels_36'\n",
    "            elif alll[0]==2:\n",
    "                imn='images_46'\n",
    "                lbn='labels_46'\n",
    "            else:\n",
    "                imn='images_57'\n",
    "                lbn='labels_57'\n",
    "                \n",
    "            try:\n",
    "                x = (np.array(hdf5file[imn][alll[1]][alll[2]])/255).T  # read dataset on the fly\n",
    "                x=np.rollaxis(x,1,0)\n",
    "\n",
    "                y = np.array(hdf5file[lbn][alll[1]][alll[2]])  # read dataset on the fly\n",
    "\n",
    "\n",
    "                if np.sum(x)==0 or np.sum(x) == np.inf or np.sum(x) == -np.inf or np.sum(y)==0 or np.sum(y)==np.inf or np.sum(y)==-np.inf:\n",
    "                    x = (np.array(hdf5file[imn]['trial_0030'][60])/255).T  # read dataset on the fly\n",
    "                    x=np.rollaxis(x,1,0)\n",
    "                    y = np.array(hdf5file[lbn]['trial_0030'][60])  # read dataset on the fly\n",
    "            except:\n",
    "                x = (np.array(hdf5file[imn]['trial_0030'][60])/255).T  # read dataset on the fly\n",
    "                x=np.rollaxis(x,1,0)\n",
    "                y = np.array(hdf5file[lbn]['trial_0030'][60])  # read dataset on the fly\n",
    "            \n",
    "\n",
    "                \n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "\n",
    "            i += 1\n",
    "#             j += 1\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        Y = np.asarray(Y)\n",
    "        yield [X,Y],[X,Y]\n",
    "        \n",
    "# idx=np.arange(len(image))\n",
    "###############################################\n",
    "##################define classes for loss and regularizor######\n",
    "def Distance(x, y):\n",
    "    d = tf.reduce_sum(tf.square(x - y), 1)\n",
    "    dx = tf.maximum(d, 1e-9)\n",
    "    dist = tf.sqrt(dx)\n",
    "    return tf.reduce_mean(dist)\n",
    "\n",
    "\n",
    "def swiss_roll(size, noise=1.5):\n",
    "    u = K.random_uniform(shape=(size[0], 1),dtype=\"float32\")\n",
    "    u2 = K.random_uniform(shape=(size[0], 1),dtype=\"float32\")*10\n",
    "\n",
    "    t = 1.5 * np.pi * (1 + 1.5* u)\n",
    "    x = t * K.cos(t)#+11*K.ones_like(u2)\n",
    "    y =  u2 #+ 11*K.ones_like(u2)\n",
    "    z = t * K.sin(t) #+ 11*K.ones_like(u2)\n",
    "\n",
    "    X = K.concatenate([x,z], axis=-1)\n",
    "\n",
    "    return X\n",
    "\n",
    "def squre_roll(size, noise=1.5):\n",
    "    u =K.random_uniform(shape=(size[0], 1),dtype=\"float32\")\n",
    "    u2 = K.random_uniform(shape=(size[0], 1),dtype=\"float32\")*10\n",
    "#     print(u)\n",
    "    t = 1.5 * np.pi * (1 + 100 * u)\n",
    "    x = t * K.cos(t)#+11*K.ones_like(u2)\n",
    "    y =  u2# + 11*K.ones_like(u2)\n",
    "    z = t * K.sin(t) #+ 11*K.ones_like(u2)\n",
    "\n",
    "    X = K.concatenate([x,y,z], axis=-1)\n",
    "\n",
    "    return X\n",
    "def spherical(size, ndim=3):\n",
    "    vec = K.random_normal(shape=(size[0], ndim),dtype=\"float32\")\n",
    "#     vec /= K.linalg.norm(vec, axis=0)\n",
    "    return vec\n",
    "\n",
    "def clusterdis(size, noise=1.5):\n",
    "    \n",
    "    a=int(size[0]/4)\n",
    "    b=a\n",
    "    c=a\n",
    "    d=size[0]-a-b-c\n",
    "    u = K.random_uniform(shape=(a, 3),dtype=\"float32\")\n",
    "    u2 = K.random_uniform(shape=(b, 3),dtype=\"float32\")*2\n",
    "    u3 = K.random_uniform(shape=(c, 3),dtype=\"float32\")*4\n",
    "    u4 = K.random_uniform(shape=(d, 3),dtype=\"float32\")*8\n",
    "#     sess = tf.Session()\n",
    "#     with sess.as_default():\n",
    "#         t=K.eval(size[0])\n",
    "    X = K.concatenate([u,u2,u3,u4], axis=0)\n",
    "\n",
    "#     X,_=make_blobs(n_samples=t, centers=4, n_features=3,random_state=42)\n",
    "    return X\n",
    "\n",
    "def GMM(size,noise=1.5):\n",
    "    \n",
    "    N,D = size[0], 3 # number of points and dimenstinality\n",
    "\n",
    "    means = np.array([[0.5, 0.0, 0.0],\n",
    "                      [0.0, 0.5, 0.8],\n",
    "                      [-0.5, -0.5, -0.5],\n",
    "                      [-0.8, 0.3, 0.4]])\n",
    "#     means= K.constant(means)\n",
    "\n",
    "    covs = np.array([np.diag([0.01, 0.01, 0.01]),\n",
    "                     np.diag([0.01, 0.01, 0.01]),\n",
    "                     np.diag([0.01, 0.01, 0.01]),\n",
    "                     np.diag([0.01, 0.01, 0.01])])\n",
    "#     covs=K.constant(covs)\n",
    "\n",
    "    n_gaussians = means.shape[0]\n",
    "\n",
    "    points = []\n",
    "    if N % 4 == 0:\n",
    "        L=int(N/4)\n",
    "        \n",
    "        \n",
    "    for i in range(len(means)):\n",
    "        x = np.random.multivariate_normal(means[i], covs[i],L)\n",
    "        points.append(x)\n",
    "\n",
    "    points=K.constant(np.concatenate(points))\n",
    "    \n",
    "    return points\n",
    "\n",
    "def get_kernel(X, Z,ksize):\n",
    "#     print(X.shape,Z.shape)\n",
    "    G = K.sum((K.expand_dims(X, axis=1) - Z)**2, axis=-1)  # Gram matrix\n",
    "    G = K.exp(-G/(ksize)) / (math.sqrt(2*np.pi*ksize)*K.ones_like(-G/(ksize)))\n",
    "    return G\n",
    "\n",
    "class DiagonalWeight(Constraint):\n",
    "    \"\"\"Constrains the weights to be diagonal.\n",
    "    \"\"\"\n",
    "    def __init__(self, N):\n",
    "        self.m = K.eye(N)\n",
    "        \n",
    "    def __call__(self, w):\n",
    "#         N = K.int_shape(w)[-1]\n",
    "#         m = K.eye(N)\n",
    "        w = w*self.m\n",
    "        return w\n",
    "    \n",
    "class KLDivergenceLayer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch =  -0.5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) - K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(tf.reduce_mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs,tf.reduce_mean(kl_batch)\n",
    "\n",
    "class ITLRegularizer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds cs divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(ITLRegularizer, self).__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "    \n",
    "    def call(self, inputs,ks,flag,theta):\n",
    "\n",
    "        X = inputs\n",
    "#         print(X)\n",
    "        if flag=='sp':\n",
    "            Z=spherical(K.shape(X))\n",
    "        elif flag == 'cb':\n",
    "            Z=clusterdis(K.shape(X))\n",
    "        elif flag == 'gmm':\n",
    "        \n",
    "            Z=GMM(K.shape(X))\n",
    "        elif flag == 'sq':\n",
    "            Z=squre_roll(K.shape(X))\n",
    "        else:\n",
    "            Z=swiss_roll(K.shape(X))\n",
    "\n",
    "    \n",
    "\n",
    "#         Z=Z.astype(\"float32\")\n",
    "        ksize=ks\n",
    "        Gxx = get_kernel(X, X,ksize)\n",
    "        Gzz = get_kernel(Z, Z,ksize)\n",
    "        Gxz = get_kernel(X, Z,ksize)\n",
    "\n",
    "\n",
    "        r=K.log(K.sqrt(K.mean(Gxx)*K.mean(Gzz)+1e-5) /(K.mean(Gxz)+1e-5))\n",
    "\n",
    "        self.add_loss(r*theta, inputs=inputs)\n",
    "\n",
    "        return inputs,Z,r*theta\n",
    "    \n",
    "class OrthLayer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(OrthLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs,gamma):\n",
    "\n",
    "        A,B = inputs\n",
    "        U=K.concatenate((A,B),axis=1)\n",
    "        U = K.l2_normalize(U, axis=1)\n",
    "        batch = -K.dot(K.transpose(U),U) \n",
    "        I =tf.eye(K.shape(U)[1])#tf.Variable(lambda:K.eye(K.shape(U)[1])) #Lambda(lambda t: K.eye(t))()\n",
    "        batch=(batch+I)**2*gamma\n",
    "        self.add_loss(tf.reduce_mean(batch), inputs=inputs)\n",
    "\n",
    "        return inputs,tf.reduce_mean(batch)\n",
    "\n",
    "    \n",
    "    \n",
    "class MSE_SUP(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(MSE_SUP, self).__init__(*args, **kwargs)\n",
    "    def call(self,inputs, alpha):\n",
    "        D,A=inputs\n",
    "        L=tf.keras.losses.mse(D,A)\n",
    "        L=tf.reduce_mean(L)\n",
    "        \n",
    "        self.add_loss(L*alpha, inputs=inputs)\n",
    "        \n",
    "        return inputs,L*alpha\n",
    "        \n",
    "    \n",
    "class MSE_UNSUP(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(MSE_UNSUP, self).__init__(*args, **kwargs)\n",
    "    def call(self,inputs):\n",
    "        D,A=inputs\n",
    "\n",
    "        L=tf.keras.losses.mse(D,A)\n",
    "        L=tf.reduce_mean(L)\n",
    "        self.add_loss(L*128*128*2, inputs=inputs)\n",
    "        \n",
    "        return inputs,L*128*128*2\n",
    "    \n",
    "    \n",
    "LN2PI=np.log(2 * 3.1415926)\n",
    "\n",
    "\n",
    "\n",
    "class De_KL(Layer):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(De_KL, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def _gaussian_log_density_unsummed(self,z, mu, logvar):\n",
    "        \"\"\"First step of Gaussian log-density computation, without summing over dimensions.\n",
    "        Assumes a diagonal noise covariance matrix.\n",
    "        \"\"\"\n",
    "        diff_sq = (z - mu) ** 2\n",
    "        inv_var = K.exp(-logvar)\n",
    "        return - 0.5 * (inv_var * diff_sq + logvar + LN2PI)\n",
    "\n",
    "\n",
    "    def _gaussian_log_density_unsummed_std_normal(self,z):\n",
    "        \"\"\"First step of Gaussian log-density computation, without summing over dimensions.\n",
    "        Assumes a diagonal noise covariance matrix.\n",
    "        \"\"\"\n",
    "        diff_sq = z ** 2\n",
    "        return - 0.5 * (diff_sq + LN2PI)\n",
    "\n",
    "    \n",
    "    def _logsumexp(self,x, axis=None, keepdims=False):\n",
    "\n",
    "        x = tf.convert_to_tensor(x)\n",
    "        x_max = tf.math.reduce_max(x, axis=axis, keepdims=False)\n",
    "        temp=tf.math.reduce_sum(K.exp(x - x_max)+1, axis=axis,keepdims=True)\n",
    "        ret = K.log(tf.math.reduce_max(temp+1,tf.zeros_like(temp+1))) + x_max\n",
    "#         np.log(np.max(x, 1e-9))\n",
    "        if not keepdims:\n",
    "            ret = tf.math.reduce_sum(ret, axis=axis)\n",
    "#         print(K.sum(x,axis=1).numpy())\n",
    "        return ret#K.sum(x,axis=1)\n",
    "\n",
    "    \n",
    "    def call(self,inputs,beta):\n",
    "        z, mu, logvar=inputs\n",
    "        log_qz_prob = self._gaussian_log_density_unsummed(z[:, None], mu[None, :], logvar[None, :])\n",
    "        M =tf.nn.relu(K.sum(log_qz_prob, axis=2, keepdims=False))#,axis=1,keepdims=False)\n",
    "        c =tf.nn.relu(log_qz_prob)#,axis=1,keepdims=False)\n",
    "        t1=K.sum(K.exp(-M)+K.exp(K.sum(log_qz_prob, axis=2, keepdims=False)-M),axis=1,keepdims=False)\n",
    "        log_qz= K.log(t1+1e-5)\n",
    "        #tf.reduce_logsumexp(K.sum(log_qz_prob, axis=2, keepdims=False),axis=1,keepdims=False)\n",
    "       \n",
    "        \n",
    "        #self._logsumexp(K.sum(log_qz_prob, axis=2, keepdims=False),axis=1,keepdims=False)\n",
    "        \n",
    "        \n",
    "#         print(log_qz.shape)\n",
    "        \n",
    "        log_qz_ = tf.linalg.diag(M) # sum over gaussian dims\n",
    "        \n",
    "#         print(log_qz_.shape)\n",
    "        t2=K.sum(K.exp(-c)+K.exp(log_qz_prob-c),axis=1,keepdims=False)\n",
    "        log_qz_product = K.sum(#log_qz_prob,\n",
    "#             K.sum(K.log(K.exp(-c)+K.exp(log_qz_prob-c)),axis=1,keepdims=False),\n",
    "#             self._logsumexp(log_qz_prob, axis=1,keepdims=False),\n",
    "            K.log(t2+1e-5),\n",
    "#             tf.reduce_logsumexp(log_qz_prob, axis=1,keepdims=False),  # logsumexp over batch\n",
    "            axis=1,  # sum over gaussian dims\n",
    "            keepdims=False)\n",
    "        \n",
    "        log_pz_prob = self._gaussian_log_density_unsummed_std_normal(z)\n",
    "        log_pz_product = K.sum(log_pz_prob, axis=1, keepdims=False)  # sum over gaussian dims\n",
    "#         print(log_qz_.shape , log_qz.shape)\n",
    "        idx_code_mi = tf.experimental.numpy.nanmean(log_qz_ - log_qz)\n",
    "        total_corr = tf.experimental.numpy.nanmean(log_qz - log_qz_product)\n",
    "        dim_wise_kl = tf.experimental.numpy.nanmean(log_qz_product - log_pz_product)\n",
    "        idx_code_mi = tf.reduce_mean(idx_code_mi )\n",
    "        total_corr = tf.reduce_mean(total_corr )\n",
    "        dim_wise_kl = tf.reduce_mean(dim_wise_kl)\n",
    "        self.add_loss((idx_code_mi+total_corr *beta+dim_wise_kl+1e-5), inputs=inputs)\n",
    "        \n",
    "        return inputs,[idx_code_mi,total_corr *beta,dim_wise_kl]\n",
    "###############################################\n",
    "input0 = Input(shape=(128,128,2), name=\"mice1\")\n",
    "# encoder=Sequential()\n",
    "inputlabel=Input(shape=(sdim), name=\"micelabel1\")\n",
    "\n",
    "encoder=LeakyReLU(alpha=0.05)(Conv2D(32, (5,5), strides= (2,2),padding='same', kernel_initializer=\"he_normal\")(input0))\n",
    "encoder=BatchNormalization()(encoder)\n",
    "# print(encoder.shape)\n",
    "encoder=LeakyReLU(alpha=0.05)(Conv2D(64, (5,5), strides= (2,2),padding='same', kernel_initializer=\"he_normal\")(encoder))\n",
    "encoder=BatchNormalization()(encoder)\n",
    "# print(encoder.shape)\n",
    "encoder=LeakyReLU(alpha=0.05)(Conv2D(128, (5,5), strides=(2,2),padding='same', kernel_initializer=\"he_normal\")(encoder))\n",
    "encoder=BatchNormalization()(encoder)\n",
    "# print(encoder.shape)\n",
    "encoder=LeakyReLU(alpha=0.05)(Conv2D(256, (5,5), strides= (2,2),padding='same', kernel_initializer=\"he_normal\")(encoder))\n",
    "encoder=BatchNormalization()(encoder)\n",
    "# print(encoder.shape)\n",
    "encoder=LeakyReLU(alpha=0.05)(Conv2D(512, (5,5), strides= (2,2),padding='same', kernel_initializer=\"he_normal\")(encoder))\n",
    "encoder=BatchNormalization()(encoder)\n",
    "# print(encoder.shape)\n",
    "hidden=Flatten()(encoder)\n",
    "# hidden.shape\n",
    "\n",
    "z_mu = Dense(latent_dim,kernel_regularizer='l1_l2')(hidden)\n",
    "z_log_var = Dense(sdim+udim,kernel_regularizer='l1_l2')(hidden)\n",
    "#\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "m = ortho_group.rvs(dim=latent_dim).astype('float32')\n",
    "\n",
    "from scipy.linalg import qr\n",
    "\n",
    "n = sdim+udim+bac\n",
    "H = np.random.randn(n, n)\n",
    "Q, _ = qr(H)\n",
    "\n",
    "initializer = tf.keras.initializers.Orthogonal()\n",
    "initializera=tf.keras.initializers.Orthogonal(gain=1.0, seed=42)\n",
    "initializerb=tf.keras.initializers.Orthogonal(gain=2.0, seed=30)\n",
    "\n",
    "\n",
    "class FixWeights_sup(tf.keras.constraints.Constraint):\n",
    "\n",
    "    def __call__(self, w):\n",
    "        tf.keras.backend.set_value(w, Q[:sdim,:sdim])\n",
    "        return w\n",
    "class FixWeights_unsup(tf.keras.constraints.Constraint):\n",
    "\n",
    "    def __call__(self, w):\n",
    "        tf.keras.backend.set_value(w, Q[sdim:sdim+udim,sdim:sdim+udim])\n",
    "        return w\n",
    "    \n",
    "class FixWeights_bac(tf.keras.constraints.Constraint):\n",
    "\n",
    "    def __call__(self, w):\n",
    "        tf.keras.backend.set_value(w, Q[sdim+udim:sdim+udim+bac-1,sdim+udim:sdim+udim+bac-1])\n",
    "        return w\n",
    "\n",
    "C1 = Dense(bac, use_bias=False,kernel_regularizer='l1_l2')#(z_mu)\n",
    "A1 = Dense(sdim,use_bias=False,kernel_initializer=initializera,kernel_regularizer='l1_l2')#(z_mu)\n",
    "B1 = Dense(udim, use_bias=False, kernel_initializer=initializerb,kernel_regularizer='l1_l2')#(z_mu)\n",
    "\n",
    "\n",
    "z_log_var_A=z_log_var[:,:sdim]\n",
    "z_log_var_B=z_log_var[:,sdim:]\n",
    "\n",
    "\n",
    "\n",
    "A1.trainable = False\n",
    "B1.trainable = False\n",
    "\n",
    "A2 = A1(z_mu)\n",
    "B = B1(z_mu)\n",
    "C = C1(z_mu)\n",
    "\n",
    "C,dis,loss2= ITLRegularizer()(C,ks,flag,theta)\n",
    "\n",
    "D1=Dense(sdim,use_bias=True,kernel_constraint=DiagonalWeight(sdim), kernel_initializer=\"he_normal\")(A2)\n",
    "[D,A3],loss3=MSE_SUP()([D1,inputlabel],alpha)\n",
    "\n",
    "[A, z_log_var_A2],loss4 = KLDivergenceLayer()([A2, z_log_var[:,:sdim]])\n",
    "z_sigma_A = Lambda(lambda t: K.exp(.5*t))(z_log_var_A2)\n",
    "\n",
    "eps_A = K.random_normal(shape=(K.shape(input0)[0],sdim))\n",
    "z_eps_A2 = Multiply()([z_sigma_A, eps_A])#Multiply()([z_sigma_A, eps_A])\n",
    "z_A = Add()([A, z_eps_A2])\n",
    "\n",
    "z_sigma_B = Lambda(lambda t: K.exp(.5*t))(z_log_var[:,sdim:])\n",
    "eps_B = K.random_normal(shape=(K.shape(input0)[0],udim))\n",
    "z_eps_B = Multiply()([z_sigma_B, eps_B])\n",
    "z_B = Add()([B, z_eps_B])\n",
    "\n",
    "[z_B1, B1, z_log_var_B1],[loss5,loss6,loss7]= De_KL()([z_B, B, z_log_var_B],beta)\n",
    "\n",
    "\n",
    "alla=Concatenate()([z_A,z_B1,C])\n",
    "\n",
    "\n",
    "# print(zall.shape)\n",
    "decoder = Sequential()\n",
    "decoder.add(Dense(hidden.shape[1], kernel_initializer=\"he_normal\"))\n",
    "decoder.add(Reshape((4, 4, 512)))\n",
    "decoder.add(Conv2DTranspose(256, (5,5), strides= (2,2),padding='same', kernel_initializer=\"he_normal\"))\n",
    "decoder.add(LeakyReLU(alpha=0.05))\n",
    "decoder.add(BatchNormalization())\n",
    "\n",
    "decoder.add(Conv2DTranspose(128, (5,5), strides= (2,2),padding='same', kernel_initializer=\"he_normal\"))\n",
    "decoder.add(LeakyReLU(alpha=0.05))\n",
    "decoder.add(BatchNormalization())\n",
    "\n",
    "decoder.add(Conv2DTranspose(64, (5,5), strides= (2,2),padding='same', kernel_initializer=\"he_normal\"))\n",
    "decoder.add(LeakyReLU(alpha=0.05))\n",
    "decoder.add(BatchNormalization())\n",
    "\n",
    "decoder.add(Conv2DTranspose(32, (5,5), strides= (2,2),padding='same', kernel_initializer=\"he_normal\"))\n",
    "decoder.add(LeakyReLU(alpha=0.05))\n",
    "decoder.add(BatchNormalization())\n",
    "\n",
    "decoder.add(Conv2DTranspose(2, (5,5), strides= (2,2),activation='sigmoid',padding='same', kernel_initializer=\"he_normal\"))\n",
    "\n",
    "encmodel = Model(inputs=[input0,inputlabel], outputs=alla)\n",
    "\n",
    "out=decoder(alla)\n",
    "[out,_],loss8=MSE_UNSUP()([out,input0])\n",
    "\n",
    "\n",
    "\n",
    "allmodel= Model(inputs=[input0,inputlabel], outputs=[out,D])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001,clipvalue=1.0)\n",
    "\n",
    "allmodel.add_metric(loss2, \"csd_loss\")\n",
    "allmodel.add_metric(loss3, \"sup_loss\")\n",
    "allmodel.add_metric(loss4, \"kl_loss\")\n",
    "allmodel.add_metric(loss5, \"mi_loss\")\n",
    "allmodel.add_metric(loss6, \"total_corr\")\n",
    "allmodel.add_metric(loss7, \"dim_wise_kl\")\n",
    "allmodel.add_metric(loss8, \"UNSUP_loss\")\n",
    "\n",
    "allmodel.compile( optimizer=optimizer)\n",
    "\n",
    "\n",
    "callbacks=[LearningRateScheduler(lambda epoch: 0.001 * 0.85 ** (epoch // 5))]\n",
    "term=tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "\n",
    "\n",
    "history1 =allmodel.fit( data_generator(index, a,256,True),validation_data=data_generator(index[-10000:],a,100,False),\n",
    "                       batch_size=256, epochs=50,validation_steps=np.ceil(10000/100-1),\n",
    "                       verbose=1, steps_per_epoch=np.ceil((len(index))/256-1),\n",
    "                       callbacks=[term,callbacks])\n",
    "\n",
    "allmodel.save_weights('model.h5')\n",
    "\n",
    "# allmodel.load_weights('csdmodel_4_udim=2_alpha=1000_beta=5_gamma=1000_theta=500_ks=15_flag=sror3.h5')###!!!!!!!\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a824c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
